{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "This notebook should include preliminary and baseline modeling.\n",
    "- Try as many different models as possible.\n",
    "- Don't worry about hyperparameter tuning or cross validation here.\n",
    "- Ideas include:\n",
    "    - linear regression\n",
    "    - support vector machines\n",
    "    - random forest\n",
    "    - xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3381, 34)\n",
      "y_train shape: (3381, 1)\n",
      "X_test shape: (1450, 34)\n",
      "y_test shape: (1450, 1)\n"
     ]
    }
   ],
   "source": [
    "#Import preprocessed data\n",
    "import pandas as pd\n",
    "\n",
    "#Independant variable training data\n",
    "X_train = pd.read_csv(\"../data/preprocessed/X_train_scaled.csv\")\n",
    "X_train = X_train.drop(columns=[\"Unnamed: 0\"])\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "\n",
    "#Target training data\n",
    "y_train = pd.read_csv(\"../data/preprocessed/y_train.csv\")\n",
    "y_train = y_train.drop(columns=[\"Unnamed: 0\"])\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "\n",
    "#Independant variable test data\n",
    "X_test = pd.read_csv(\"../data/preprocessed/X_test_scaled.csv\")\n",
    "X_test = X_test.drop(columns=[\"Unnamed: 0\"])\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "#Target test data\n",
    "y_test = pd.read_csv(\"../data/preprocessed/y_test.csv\")\n",
    "y_test = y_test.drop(columns=[\"Unnamed: 0\"])\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function to get all error scores at once\n",
    "def get_error_scores (y_train, y_train_pred, y_test, y_test_pred, error_type='All', num_results=10):\n",
    "    # Check performance on train and test set\n",
    "    from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "    import numpy as np\n",
    "\n",
    "    if (error_type == 'All' or LOWER(error_type) == 'r2'):\n",
    "        #Using R2\n",
    "        r2_train = round(r2_score(y_train, y_train_pred),4)\n",
    "        r2_test = round(r2_score(y_test, y_test_pred),4)\n",
    "\n",
    "        print(f'R SQUARED\\n\\tTrain R2:\\t{r2_train}\\n\\tTest R2:\\t{r2_test}')\n",
    "\n",
    "    if (error_type == 'All' or LOWER(error_type) == 'mae'):\n",
    "        #Using Mean Average Error\n",
    "        MAE_train = round(mean_absolute_error(y_train, y_train_pred),2)\n",
    "        MAE_test = round(mean_absolute_error(y_test, y_test_pred),2)\n",
    "\n",
    "        print(f'MEAN AVERAGE ERROR\\n\\tTrain MAE:\\t{MAE_train}\\n\\tTest MAE:\\t{MAE_test}')\n",
    "\n",
    "    if (error_type == 'All' or LOWER(error_type) == 'rmse'):\n",
    "        #Using Root Mean Squared Error\n",
    "        RMSE_train = round(np.sqrt(mean_squared_error(y_train, y_train_pred)),2)\n",
    "        RMSE_test = round(np.sqrt(mean_squared_error(y_test, y_test_pred)),2)\n",
    "\n",
    "        print(f'ROOT MEAN SQUARED ERROR\\n\\tTrain RMSE:\\t{RMSE_train}\\n\\tTest RMSE:\\t{RMSE_test}\\n')\n",
    "\n",
    "    if (error_type == 'All'):\n",
    "        display_results_sample(y_test, y_test_pred, num_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to demonstrate of prediction\n",
    "def display_results_sample (y_test, y_test_prediction, num_results=10):\n",
    "    import random\n",
    "\n",
    "    print(f\"{num_results} Randomly selected results.\")\n",
    "\n",
    "    sum_percentage_error = 0\n",
    "\n",
    "    #Choose 10 rows to display\n",
    "    for i in range(num_results):\n",
    "        j = random.randint(0, len(y_test)-1)\n",
    "\n",
    "        demo_prediction = round(y_test_prediction[j][0])\n",
    "        demo_actual = round(y_test.iloc[j].item())\n",
    "        demo_difference = demo_prediction - demo_actual\n",
    "        demo_difference_percentage = round((demo_actual / demo_prediction - 1)*100,2)\n",
    "\n",
    "        sum_percentage_error += abs(demo_difference_percentage)\n",
    "\n",
    "        print(f\"Index: {j} \\t- \\tPrediction: ${demo_prediction:,} \\tActual: ${demo_actual:,} \\tDifference: {demo_difference:,}, {demo_difference_percentage}%\")\n",
    "\n",
    "    average_percentage_error = round(sum_percentage_error / num_results,2)\n",
    "    print(f\"\\t\\t\\t\\t\\t\\t\\t\\t\\tAverage % error = {average_percentage_error}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider what metrics you want to use to evaluate success.\n",
    "- If you think about mean squared error, can we actually relate to the amount of error?\n",
    "- Try root mean squared error so that error is closer to the original units (dollars)\n",
    "- What does RMSE do to outliers?\n",
    "- Is mean absolute error a good metric for this problem?\n",
    "- What about R^2? Adjusted R^2?\n",
    "- Briefly describe your reasons for picking the metrics you use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R SQUARED\n",
      "\tTrain R2:\t0.7374\n",
      "\tTest R2:\t0.7271\n",
      "MEAN AVERAGE ERROR\n",
      "\tTrain MAE:\t69045.11\n",
      "\tTest MAE:\t69106.02\n",
      "ROOT MEAN SQUARED ERROR\n",
      "\tTrain RMSE:\t94173.5\n",
      "\tTest RMSE:\t95747.86\n",
      "\n",
      "10 Randomly selected results.\n",
      "Index: 1356 \t- \tPrediction: $186,969 \tActual: $150,000 \tDifference: 36,969, -19.77%\n",
      "Index: 225 \t- \tPrediction: $567,266 \tActual: $762,000 \tDifference: -194,734, 34.33%\n",
      "Index: 1247 \t- \tPrediction: $446,066 \tActual: $280,000 \tDifference: 166,066, -37.23%\n",
      "Index: 1379 \t- \tPrediction: $563,924 \tActual: $368,000 \tDifference: 195,924, -34.74%\n",
      "Index: 1110 \t- \tPrediction: $51,367 \tActual: $100,000 \tDifference: -48,633, 94.68%\n",
      "Index: 84 \t- \tPrediction: $614,979 \tActual: $651,000 \tDifference: -36,021, 5.86%\n",
      "Index: 40 \t- \tPrediction: $164,046 \tActual: $153,000 \tDifference: 11,046, -6.73%\n",
      "Index: 396 \t- \tPrediction: $372,689 \tActual: $270,000 \tDifference: 102,689, -27.55%\n",
      "Index: 594 \t- \tPrediction: $299,558 \tActual: $245,000 \tDifference: 54,558, -18.21%\n",
      "Index: 820 \t- \tPrediction: $356,691 \tActual: $299,000 \tDifference: 57,691, -16.17%\n",
      "\t\t\t\t\t\t\t\t\tAverage % error = 29.53%\n"
     ]
    }
   ],
   "source": [
    "# Train our Linear Regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "#Get predictions\n",
    "y_train_pred = reg.predict(X_train)\n",
    "y_test_pred = reg.predict(X_test)\n",
    "\n",
    "get_error_scores (y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of polynomial features: 630\n",
      "R SQUARED\n",
      "\tTrain R2:\t0.8911\n",
      "\tTest R2:\t0.8373\n",
      "MEAN AVERAGE ERROR\n",
      "\tTrain MAE:\t45371.38\n",
      "\tTest MAE:\t54898.79\n",
      "ROOT MEAN SQUARED ERROR\n",
      "\tTrain RMSE:\t60651.3\n",
      "\tTest RMSE:\t73930.9\n",
      "\n",
      "10 Randomly selected results.\n",
      "Index: 638 \t- \tPrediction: $531,926 \tActual: $550,000 \tDifference: -18,074, 3.4%\n",
      "Index: 1389 \t- \tPrediction: $253,862 \tActual: $145,000 \tDifference: 108,862, -42.88%\n",
      "Index: 313 \t- \tPrediction: $487,708 \tActual: $529,900 \tDifference: -42,192, 8.65%\n",
      "Index: 1382 \t- \tPrediction: $221,235 \tActual: $315,000 \tDifference: -93,765, 42.38%\n",
      "Index: 972 \t- \tPrediction: $39,779 \tActual: $74,250 \tDifference: -34,471, 86.66%\n",
      "Index: 283 \t- \tPrediction: $486,318 \tActual: $450,000 \tDifference: 36,318, -7.47%\n",
      "Index: 73 \t- \tPrediction: $510,943 \tActual: $785,000 \tDifference: -274,057, 53.64%\n",
      "Index: 834 \t- \tPrediction: $313,310 \tActual: $200,000 \tDifference: 113,310, -36.17%\n",
      "Index: 1108 \t- \tPrediction: $256,544 \tActual: $288,000 \tDifference: -31,456, 12.26%\n",
      "Index: 485 \t- \tPrediction: $171,267 \tActual: $106,000 \tDifference: 65,267, -38.11%\n",
      "\t\t\t\t\t\t\t\t\tAverage % error = 33.16%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Create 2nd degree polynomial feature set and train model\n",
    "poly2 = PolynomialFeatures(degree=2)\n",
    "Xpoly_train = poly2.fit_transform(X_train)\n",
    "Xpoly_test = poly2.transform(X_test)\n",
    "print(f'Number of polynomial features: {Xpoly_train.shape[1]}')\n",
    "\n",
    "# Train our model\n",
    "reg.fit(Xpoly_train, y_train)\n",
    "ypoly_train_pred = reg.predict(Xpoly_train)\n",
    "ypoly_test_pred = reg.predict(Xpoly_test)\n",
    "\n",
    "get_error_scores(y_train, ypoly_train_pred, y_test, ypoly_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of polynomial features: 7770\n",
      "R SQUARED\n",
      "\tTrain R2:\t1.0\n",
      "\tTest R2:\t0.9693\n",
      "MEAN AVERAGE ERROR\n",
      "\tTrain MAE:\t0.0\n",
      "\tTest MAE:\t4554.24\n",
      "ROOT MEAN SQUARED ERROR\n",
      "\tTrain RMSE:\t0.0\n",
      "\tTest RMSE:\t32094.95\n",
      "\n",
      "10 Randomly selected results.\n",
      "Index: 583 \t- \tPrediction: $276,000 \tActual: $276,000 \tDifference: 0, 0.0%\n",
      "Index: 927 \t- \tPrediction: $162,000 \tActual: $162,000 \tDifference: 0, 0.0%\n",
      "Index: 724 \t- \tPrediction: $415,000 \tActual: $415,000 \tDifference: 0, 0.0%\n",
      "Index: 1195 \t- \tPrediction: $550,000 \tActual: $550,000 \tDifference: 0, 0.0%\n",
      "Index: 9 \t- \tPrediction: $379,000 \tActual: $379,000 \tDifference: 0, 0.0%\n",
      "Index: 32 \t- \tPrediction: $515,000 \tActual: $515,000 \tDifference: 0, 0.0%\n",
      "Index: 97 \t- \tPrediction: $260,000 \tActual: $260,000 \tDifference: 0, 0.0%\n",
      "Index: 1345 \t- \tPrediction: $559,900 \tActual: $559,900 \tDifference: 0, 0.0%\n",
      "Index: 1127 \t- \tPrediction: $100,000 \tActual: $100,000 \tDifference: 0, 0.0%\n",
      "Index: 80 \t- \tPrediction: $371,500 \tActual: $371,500 \tDifference: 0, 0.0%\n",
      "\t\t\t\t\t\t\t\t\tAverage % error = 0.0%\n"
     ]
    }
   ],
   "source": [
    "# Create polynomial feature set and train model\n",
    "poly2 = PolynomialFeatures(degree=3)\n",
    "Xpoly_train = poly2.fit_transform(X_train)\n",
    "Xpoly_test = poly2.transform(X_test)\n",
    "print(f'Number of polynomial features: {Xpoly_train.shape[1]}')\n",
    "\n",
    "# Train our model\n",
    "reg.fit(Xpoly_train, y_train)\n",
    "ypoly_train_pred = reg.predict(Xpoly_train)\n",
    "ypoly_test_pred = reg.predict(Xpoly_test)\n",
    "\n",
    "# Check performance on train and test set\n",
    "get_error_scores(y_train, ypoly_train_pred, y_test, ypoly_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection - STRETCH\n",
    "\n",
    "> **This step doesn't need to be part of your Minimum Viable Product (MVP), but its recommended you complete it if you have time!**\n",
    "\n",
    "Even with all the preprocessing we did in Notebook 1, you probably still have a lot of features. Are they all important for prediction?\n",
    "\n",
    "Investigate some feature selection algorithms (Lasso, RFE, Forward/Backward Selection)\n",
    "- Perform feature selection to get a reduced subset of your original features\n",
    "- Refit your models with this reduced dimensionality - how does performance change on your chosen metrics?\n",
    "- Based on this, should you include feature selection in your final pipeline? Explain\n",
    "\n",
    "Remember, feature selection often doesn't directly improve performance, but if performance remains the same, a simpler model is often preferrable. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform feature selection \n",
    "# refit models\n",
    "# gather evaluation metrics and compare to the previous step (full feature set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhl_env",
   "language": "python",
   "name": "lhl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
