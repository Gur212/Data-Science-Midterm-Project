{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "This notebook should include preliminary and baseline modeling.\n",
    "- Try as many different models as possible.\n",
    "- Don't worry about hyperparameter tuning or cross validation here.\n",
    "- Ideas include:\n",
    "    - linear regression\n",
    "    - support vector machines\n",
    "    - random forest\n",
    "    - xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3381, 34)\n",
      "y_train shape: (3381, 1)\n",
      "X_test shape: (1450, 34)\n",
      "y_test shape: (1450, 1)\n"
     ]
    }
   ],
   "source": [
    "#Import preprocessed data\n",
    "import pandas as pd\n",
    "\n",
    "#Independant variable training data\n",
    "X_train = pd.read_csv(\"../data/preprocessed/X_train_scaled.csv\")\n",
    "X_train = X_train.drop(columns=[\"Unnamed: 0\"])\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "\n",
    "#Target training data\n",
    "y_train = pd.read_csv(\"../data/preprocessed/y_train.csv\")\n",
    "y_train = y_train.drop(columns=[\"Unnamed: 0\"])\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "\n",
    "#Independant variable test data\n",
    "X_test = pd.read_csv(\"../data/preprocessed/X_test_scaled.csv\")\n",
    "X_test = X_test.drop(columns=[\"Unnamed: 0\"])\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "#Target test data\n",
    "y_test = pd.read_csv(\"../data/preprocessed/y_test.csv\")\n",
    "y_test = y_test.drop(columns=[\"Unnamed: 0\"])\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function to get all error scores at once\n",
    "def get_error_scores (y_train, y_train_pred, y_test, y_test_pred, error_type='All', num_results=10):\n",
    "    # Check performance on train and test set\n",
    "    from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "    import numpy as np\n",
    "\n",
    "    if (error_type == 'All' or LOWER(error_type) == 'r2'):\n",
    "        #Using R2\n",
    "        r2_train = round(r2_score(y_train, y_train_pred),4)\n",
    "        r2_test = round(r2_score(y_test, y_test_pred),4)\n",
    "\n",
    "        print(f'R SQUARED\\n\\tTrain R²:\\t{r2_train}\\n\\tTest R²:\\t{r2_test}')\n",
    "\n",
    "    if (error_type == 'All' or LOWER(error_type) == 'mae'):\n",
    "        #Using Mean Average Error\n",
    "        MAE_train = round(mean_absolute_error(y_train, y_train_pred),2)\n",
    "        MAE_test = round(mean_absolute_error(y_test, y_test_pred),2)\n",
    "\n",
    "        print(f'MEAN AVERAGE ERROR\\n\\tTrain MAE:\\t{MAE_train}\\n\\tTest MAE:\\t{MAE_test}')\n",
    "\n",
    "    if (error_type == 'All' or LOWER(error_type) == 'rmse'):\n",
    "        #Using Root Mean Squared Error\n",
    "        RMSE_train = round(np.sqrt(mean_squared_error(y_train, y_train_pred)),2)\n",
    "        RMSE_test = round(np.sqrt(mean_squared_error(y_test, y_test_pred)),2)\n",
    "\n",
    "        print(f'ROOT MEAN SQUARED ERROR\\n\\tTrain RMSE:\\t{RMSE_train}\\n\\tTest RMSE:\\t{RMSE_test}\\n')\n",
    "\n",
    "    if (error_type == 'All'):\n",
    "        display_results_sample(y_test, y_test_pred, num_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to demonstrate of prediction\n",
    "def display_results_sample (y_test, y_test_prediction, num_results=10):\n",
    "    import random\n",
    "\n",
    "    print(f\"{num_results} Randomly selected results.\")\n",
    "\n",
    "    sum_percentage_error = 0\n",
    "\n",
    "    #Choose 10 rows to display\n",
    "    for i in range(num_results):\n",
    "        j = random.randint(0, len(y_test)-1)\n",
    "\n",
    "        if isinstance(y_test_prediction[j], (list, tuple, np.ndarray)):\n",
    "            demo_prediction = round(y_test_prediction[j][0])\n",
    "        else:\n",
    "            demo_prediction = round(y_test_prediction[j])\n",
    "        demo_actual = round(y_test.iloc[j].item())\n",
    "        demo_difference = demo_prediction - demo_actual\n",
    "        demo_difference_percentage = round((demo_actual / demo_prediction - 1)*100,2)\n",
    "\n",
    "        sum_percentage_error += abs(demo_difference_percentage)\n",
    "\n",
    "        print(f\"Index: {j} \\t- \\tPrediction: ${demo_prediction:,} \\tActual: ${demo_actual:,} \\tDifference: {demo_difference:,}, {demo_difference_percentage}%\")\n",
    "\n",
    "    average_percentage_error = round(sum_percentage_error / num_results,2)\n",
    "    print(f\"\\t\\t\\t\\t\\t\\t\\t\\t\\tAverage % error = {average_percentage_error}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider what metrics you want to use to evaluate success.\n",
    "- If you think about mean squared error, can we actually relate to the amount of error?\n",
    "- Try root mean squared error so that error is closer to the original units (dollars)\n",
    "- What does RMSE do to outliers?\n",
    "- Is mean absolute error a good metric for this problem?\n",
    "- What about R^2? Adjusted R^2?\n",
    "- Briefly describe your reasons for picking the metrics you use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R SQUARED\n",
      "\tTrain R²:\t0.7374\n",
      "\tTest R²:\t0.7271\n",
      "MEAN AVERAGE ERROR\n",
      "\tTrain MAE:\t69045.11\n",
      "\tTest MAE:\t69106.02\n",
      "ROOT MEAN SQUARED ERROR\n",
      "\tTrain RMSE:\t94173.5\n",
      "\tTest RMSE:\t95747.86\n",
      "\n",
      "10 Randomly selected results.\n",
      "Index: 676 \t- \tPrediction: $143,842 \tActual: $115,000 \tDifference: 28,842, -20.05%\n",
      "Index: 1373 \t- \tPrediction: $252,778 \tActual: $226,000 \tDifference: 26,778, -10.59%\n",
      "Index: 1118 \t- \tPrediction: $493,557 \tActual: $475,000 \tDifference: 18,557, -3.76%\n",
      "Index: 184 \t- \tPrediction: $457,896 \tActual: $750,000 \tDifference: -292,104, 63.79%\n",
      "Index: 700 \t- \tPrediction: $407,926 \tActual: $357,000 \tDifference: 50,926, -12.48%\n",
      "Index: 626 \t- \tPrediction: $324,631 \tActual: $206,000 \tDifference: 118,631, -36.54%\n",
      "Index: 1356 \t- \tPrediction: $186,969 \tActual: $150,000 \tDifference: 36,969, -19.77%\n",
      "Index: 1390 \t- \tPrediction: $135,279 \tActual: $160,000 \tDifference: -24,721, 18.27%\n",
      "Index: 314 \t- \tPrediction: $213,259 \tActual: $195,000 \tDifference: 18,259, -8.56%\n",
      "Index: 799 \t- \tPrediction: $161,340 \tActual: $135,000 \tDifference: 26,340, -16.33%\n",
      "\t\t\t\t\t\t\t\t\tAverage % error = 21.01%\n"
     ]
    }
   ],
   "source": [
    "# Train our Linear Regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "#Get predictions\n",
    "y_train_pred = reg.predict(X_train)\n",
    "y_test_pred = reg.predict(X_test)\n",
    "\n",
    "get_error_scores (y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of polynomial features: 630\n",
      "R SQUARED\n",
      "\tTrain R²:\t0.8911\n",
      "\tTest R²:\t0.8373\n",
      "MEAN AVERAGE ERROR\n",
      "\tTrain MAE:\t45371.38\n",
      "\tTest MAE:\t54898.79\n",
      "ROOT MEAN SQUARED ERROR\n",
      "\tTrain RMSE:\t60651.3\n",
      "\tTest RMSE:\t73930.9\n",
      "\n",
      "10 Randomly selected results.\n",
      "Index: 477 \t- \tPrediction: $394,945 \tActual: $385,000 \tDifference: 9,945, -2.52%\n",
      "Index: 778 \t- \tPrediction: $539,000 \tActual: $730,000 \tDifference: -191,000, 35.44%\n",
      "Index: 776 \t- \tPrediction: $426,494 \tActual: $599,000 \tDifference: -172,506, 40.45%\n",
      "Index: 123 \t- \tPrediction: $170,401 \tActual: $195,000 \tDifference: -24,599, 14.44%\n",
      "Index: 1185 \t- \tPrediction: $321,031 \tActual: $326,000 \tDifference: -4,969, 1.55%\n",
      "Index: 1202 \t- \tPrediction: $673,631 \tActual: $705,000 \tDifference: -31,369, 4.66%\n",
      "Index: 165 \t- \tPrediction: $421,616 \tActual: $487,000 \tDifference: -65,384, 15.51%\n",
      "Index: 1014 \t- \tPrediction: $192,863 \tActual: $180,000 \tDifference: 12,863, -6.67%\n",
      "Index: 1361 \t- \tPrediction: $407,017 \tActual: $325,000 \tDifference: 82,017, -20.15%\n",
      "Index: 1261 \t- \tPrediction: $635,597 \tActual: $700,000 \tDifference: -64,403, 10.13%\n",
      "\t\t\t\t\t\t\t\t\tAverage % error = 15.15%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Create 2nd degree polynomial feature set and train model\n",
    "poly2 = PolynomialFeatures(degree=2)\n",
    "Xpoly_train = poly2.fit_transform(X_train)\n",
    "Xpoly_test = poly2.transform(X_test)\n",
    "print(f'Number of polynomial features: {Xpoly_train.shape[1]}')\n",
    "\n",
    "# Train our model\n",
    "reg.fit(Xpoly_train, y_train)\n",
    "ypoly_train_pred = reg.predict(Xpoly_train)\n",
    "ypoly_test_pred = reg.predict(Xpoly_test)\n",
    "\n",
    "get_error_scores(y_train, ypoly_train_pred, y_test, ypoly_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of polynomial features: 7770\n",
      "R SQUARED\n",
      "\tTrain R²:\t1.0\n",
      "\tTest R²:\t0.9693\n",
      "MEAN AVERAGE ERROR\n",
      "\tTrain MAE:\t0.0\n",
      "\tTest MAE:\t4554.24\n",
      "ROOT MEAN SQUARED ERROR\n",
      "\tTrain RMSE:\t0.0\n",
      "\tTest RMSE:\t32094.95\n",
      "\n",
      "10 Randomly selected results.\n",
      "Index: 228 \t- \tPrediction: $415,000 \tActual: $415,000 \tDifference: 0, 0.0%\n",
      "Index: 1427 \t- \tPrediction: $299,000 \tActual: $299,000 \tDifference: 0, 0.0%\n",
      "Index: 558 \t- \tPrediction: $225,000 \tActual: $225,000 \tDifference: 0, 0.0%\n",
      "Index: 562 \t- \tPrediction: $810,000 \tActual: $810,000 \tDifference: 0, 0.0%\n",
      "Index: 433 \t- \tPrediction: $144,000 \tActual: $144,000 \tDifference: 0, 0.0%\n",
      "Index: 919 \t- \tPrediction: $400,000 \tActual: $400,000 \tDifference: 0, 0.0%\n",
      "Index: 773 \t- \tPrediction: $450,000 \tActual: $450,000 \tDifference: 0, 0.0%\n",
      "Index: 750 \t- \tPrediction: $45,000 \tActual: $45,000 \tDifference: 0, 0.0%\n",
      "Index: 228 \t- \tPrediction: $415,000 \tActual: $415,000 \tDifference: 0, 0.0%\n",
      "Index: 1298 \t- \tPrediction: $283,500 \tActual: $283,500 \tDifference: 0, 0.0%\n",
      "\t\t\t\t\t\t\t\t\tAverage % error = 0.0%\n"
     ]
    }
   ],
   "source": [
    "# Create polynomial feature set and train model\n",
    "poly2 = PolynomialFeatures(degree=3)\n",
    "Xpoly_train = poly2.fit_transform(X_train)\n",
    "Xpoly_test = poly2.transform(X_test)\n",
    "print(f'Number of polynomial features: {Xpoly_train.shape[1]}')\n",
    "\n",
    "# Train our model\n",
    "reg.fit(Xpoly_train, y_train)\n",
    "ypoly_train_pred = reg.predict(Xpoly_train)\n",
    "ypoly_test_pred = reg.predict(Xpoly_test)\n",
    "\n",
    "# Check performance on train and test set\n",
    "get_error_scores(y_train, ypoly_train_pred, y_test, ypoly_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find best model\n",
    "def find_best_regression_model (iX_train, iX_test, iy_train, iy_test):\n",
    "    #import needed modules\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from xgboost import XGBRegressor\n",
    "    from lightgbm import LGBMRegressor\n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "    #List models to discover\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Decision Tree\": DecisionTreeRegressor(),\n",
    "        \"Random Forest\": RandomForestRegressor(),\n",
    "        \"XGBoost\": XGBRegressor(),\n",
    "        \"LightGBM\": LGBMRegressor(),\n",
    "        \"Neural Network\": MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=500)\n",
    "    }\n",
    "\n",
    "    #Empty results dictionary\n",
    "    results = {}\n",
    "\n",
    "    # Train and evaluate models\n",
    "    for name, model in models.items():\n",
    "        print(f\"Processing {name}\")\n",
    "        model.fit(iX_train, iy_train)\n",
    "        iy_pred = model.predict(iX_test)\n",
    "        mse = mean_squared_error(iy_test, iy_pred)\n",
    "        r2 = r2_score(iy_test, iy_pred)\n",
    "        \n",
    "        results[name] = {\"MSE\": mse, \"R² Score\": r2}\n",
    "\n",
    "    # Convert results to DataFrame for better visualization\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    results_df_sorted = results_df.sort_values(by='R² Score', ascending=False)\n",
    "\n",
    "    print(f\"Processing COMPLETE!\")\n",
    "\n",
    "    return results_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Linear Regression\n",
      "Processing Decision Tree\n",
      "Processing Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniforge/base/lib/python3.12/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing XGBoost\n",
      "Processing LightGBM\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1805\n",
      "[LightGBM] [Info] Number of data points in the train set: 3381, number of used features: 31\n",
      "[LightGBM] [Info] Start training from score 344341.797693\n",
      "Processing Neural Network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniforge/base/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1650: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing COMPLETE!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniforge/base/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_finding_results = find_best_regression_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>R² Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>1.372788e+09</td>\n",
       "      <td>0.959128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>2.155692e+09</td>\n",
       "      <td>0.935819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>2.542771e+09</td>\n",
       "      <td>0.924294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>5.805151e+09</td>\n",
       "      <td>0.827164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>9.167652e+09</td>\n",
       "      <td>0.727053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>9.645661e+09</td>\n",
       "      <td>0.712821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            MSE  R² Score\n",
       "XGBoost            1.372788e+09  0.959128\n",
       "LightGBM           2.155692e+09  0.935819\n",
       "Random Forest      2.542771e+09  0.924294\n",
       "Decision Tree      5.805151e+09  0.827164\n",
       "Linear Regression  9.167652e+09  0.727053\n",
       "Neural Network     9.645661e+09  0.712821"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_finding_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R SQUARED\n",
      "\tTrain R²:\t0.9977\n",
      "\tTest R²:\t0.9591\n",
      "MEAN AVERAGE ERROR\n",
      "\tTrain MAE:\t5987.47\n",
      "\tTest MAE:\t22881.88\n",
      "ROOT MEAN SQUARED ERROR\n",
      "\tTrain RMSE:\t8823.46\n",
      "\tTest RMSE:\t37051.15\n",
      "\n",
      "10 Randomly selected results.\n",
      "Index: 555 \t- \tPrediction: $266,107 \tActual: $280,000 \tDifference: -13,893, 5.22%\n",
      "Index: 1315 \t- \tPrediction: $406,853 \tActual: $525,000 \tDifference: -118,147, 29.04%\n",
      "Index: 1066 \t- \tPrediction: $344,416 \tActual: $350,000 \tDifference: -5,584, 1.62%\n",
      "Index: 519 \t- \tPrediction: $225,324 \tActual: $224,325 \tDifference: 999, -0.44%\n",
      "Index: 1202 \t- \tPrediction: $689,452 \tActual: $705,000 \tDifference: -15,548, 2.26%\n",
      "Index: 526 \t- \tPrediction: $152,883 \tActual: $145,000 \tDifference: 7,883, -5.16%\n",
      "Index: 1422 \t- \tPrediction: $515,922 \tActual: $519,450 \tDifference: -3,528, 0.68%\n",
      "Index: 135 \t- \tPrediction: $219,435 \tActual: $245,000 \tDifference: -25,565, 11.65%\n",
      "Index: 995 \t- \tPrediction: $134,078 \tActual: $144,000 \tDifference: -9,922, 7.4%\n",
      "Index: 1170 \t- \tPrediction: $404,198 \tActual: $401,000 \tDifference: 3,198, -0.79%\n",
      "\t\t\t\t\t\t\t\t\tAverage % error = 6.43%\n"
     ]
    }
   ],
   "source": [
    "# Train our XG Model model\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xg = XGBRegressor()\n",
    "xg.fit(X_train, y_train)\n",
    "\n",
    "#Get predictions\n",
    "y_xg_train_pred = xg.predict(X_train)\n",
    "y_xg_test_pred = xg.predict(X_test)\n",
    "\n",
    "get_error_scores (y_train, y_xg_train_pred, y_test, y_xg_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection - STRETCH\n",
    "\n",
    "> **This step doesn't need to be part of your Minimum Viable Product (MVP), but its recommended you complete it if you have time!**\n",
    "\n",
    "Even with all the preprocessing we did in Notebook 1, you probably still have a lot of features. Are they all important for prediction?\n",
    "\n",
    "Investigate some feature selection algorithms (Lasso, RFE, Forward/Backward Selection)\n",
    "- Perform feature selection to get a reduced subset of your original features\n",
    "- Refit your models with this reduced dimensionality - how does performance change on your chosen metrics?\n",
    "- Based on this, should you include feature selection in your final pipeline? Explain\n",
    "\n",
    "Remember, feature selection often doesn't directly improve performance, but if performance remains the same, a simpler model is often preferrable. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform feature selection \n",
    "# refit models\n",
    "# gather evaluation metrics and compare to the previous step (full feature set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhl_env",
   "language": "python",
   "name": "lhl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
